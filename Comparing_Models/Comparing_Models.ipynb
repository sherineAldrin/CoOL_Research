{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fa0d0e6-7275-4a55-8205-e4904235eaa1",
   "metadata": {},
   "source": [
    "### I need to make either a box plot or violin plot for every region that we are analyzing. Each plot should be labeled with the region and each plot should have the ECCO, ASTE, ORAS5, and GLORYS boxes or violins with correspondng colors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937c3e27-80e9-484c-94e3-21f109396750",
   "metadata": {},
   "source": [
    "import the tools I may need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb0549d5-c232-4f7f-bfdb-8613fc59159e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "from matplotlib import gridspec\n",
    "import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d03c5e3a-9544-4349-a5d1-6d97a32afdd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in /Applications/miniconda3/envs/oceanModeling/lib/python3.11/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /Applications/miniconda3/envs/oceanModeling/lib/python3.11/site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.2 in /Applications/miniconda3/envs/oceanModeling/lib/python3.11/site-packages (from seaborn) (2.2.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /Applications/miniconda3/envs/oceanModeling/lib/python3.11/site-packages (from seaborn) (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Applications/miniconda3/envs/oceanModeling/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Applications/miniconda3/envs/oceanModeling/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Applications/miniconda3/envs/oceanModeling/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Applications/miniconda3/envs/oceanModeling/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Applications/miniconda3/envs/oceanModeling/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /Applications/miniconda3/envs/oceanModeling/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Applications/miniconda3/envs/oceanModeling/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Applications/miniconda3/envs/oceanModeling/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Applications/miniconda3/envs/oceanModeling/lib/python3.11/site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Applications/miniconda3/envs/oceanModeling/lib/python3.11/site-packages (from pandas>=1.2->seaborn) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /Applications/miniconda3/envs/oceanModeling/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12e85387-b38d-4659-9780-b9eab11360bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2e0af81-098a-495e-a390-ef0d2f70cedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using xarray, load all my csv files\n",
    "output_path = \"Users/sherine_aldrin/Downloads/CoOL/Comparing_Models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc15b604-706c-426f-9da7-38b5d289ef42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ECCO\n",
    "\n",
    "# Load summary difference data and region info\n",
    "#ecco_summary_path = \"/Users/sherine_aldrin/Downloads/CoOL/GreenlandModel/NEW_Files_OMG_vs_ECCO\"\n",
    "#all_csv_paths = glob.glob(os.path.join(ecco_summary_path, \"profile_summary_*.csv\"))\n",
    "#region_csv = \"/Users/sherine_aldrin/Downloads/CoOL/GreenlandModel/OMG_CTD_Locations_2016_2017_with_region.csv\"\n",
    "\n",
    "# Combine all CSVs\n",
    "ecco_csv = pd.read_csv('/Users/sherine_aldrin/Downloads/CoOL/GreenlandModel/Files_OMG_vs_ECCO/ecco_profiles_with_region.csv') #for csv in all_csv_paths]\n",
    "#ecco_csv = pd.concat(e_summary_df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c065d01-a425-44ff-9a4e-a3988cba1829",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecco_csv = ecco_csv.rename(columns={\"variable\": \"Var_type\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "802ab31b-c470-44d5-88e2-e8e05b9f1fe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>Var_type</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>ecco_mean</th>\n",
       "      <th>omg_mean</th>\n",
       "      <th>difference</th>\n",
       "      <th>ecco_profile</th>\n",
       "      <th>depth_profile</th>\n",
       "      <th>omg_profile</th>\n",
       "      <th>omg_depth</th>\n",
       "      <th>file_clean</th>\n",
       "      <th>Region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CTD_20160916_140334.nc</td>\n",
       "      <td>THETA</td>\n",
       "      <td>74.732773</td>\n",
       "      <td>-65.246246</td>\n",
       "      <td>0.457267</td>\n",
       "      <td>1.256591</td>\n",
       "      <td>0.799324</td>\n",
       "      <td>[6.908427715301514, 6.9216132164001465, 3.3188...</td>\n",
       "      <td>[5.0, 15.0, 25.0, 35.0, 45.0, 55.0, 65.0, 75.0...</td>\n",
       "      <td>[3.883240222930908, 3.85650897026062, 3.849779...</td>\n",
       "      <td>[-1.0, -2.0, -3.0, -4.0, -5.0, -6.0, -7.0, -8....</td>\n",
       "      <td>20160916_140334</td>\n",
       "      <td>NW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CTD_20160928_154417.nc</td>\n",
       "      <td>THETA</td>\n",
       "      <td>75.957336</td>\n",
       "      <td>-59.610691</td>\n",
       "      <td>1.542009</td>\n",
       "      <td>1.341167</td>\n",
       "      <td>-0.200843</td>\n",
       "      <td>[2.7182743549346924, 2.717210292816162, 2.4996...</td>\n",
       "      <td>[5.0, 15.0, 25.0, 35.0, 45.0, 55.0]</td>\n",
       "      <td>[-0.32447493076324463, -0.3700553774833679, -0...</td>\n",
       "      <td>[-1.0, -2.0, -3.0, -4.0, -5.0, -6.0, -7.0, -8....</td>\n",
       "      <td>20160928_154417</td>\n",
       "      <td>NW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CTD_20160923_153439.nc</td>\n",
       "      <td>THETA</td>\n",
       "      <td>81.222504</td>\n",
       "      <td>-64.780159</td>\n",
       "      <td>-0.851680</td>\n",
       "      <td>-0.294011</td>\n",
       "      <td>0.557669</td>\n",
       "      <td>[-1.8896114826202393, -1.8808256387710571, -1....</td>\n",
       "      <td>[5.0, 15.0, 25.0, 35.0, 45.0, 55.0, 65.0, 75.0...</td>\n",
       "      <td>[-1.5689005851745605, -1.5877989530563354, -1....</td>\n",
       "      <td>[-1.0, -2.0, -3.0, -4.0, -5.0, -6.0, -7.0, -8....</td>\n",
       "      <td>20160923_153439</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CTD_20160914_145226.nc</td>\n",
       "      <td>THETA</td>\n",
       "      <td>69.198280</td>\n",
       "      <td>-52.412819</td>\n",
       "      <td>1.602942</td>\n",
       "      <td>2.162872</td>\n",
       "      <td>0.559930</td>\n",
       "      <td>[5.706634998321533, 5.755438804626465, 4.86297...</td>\n",
       "      <td>[5.0, 15.0, 25.0, 35.0, 45.0, 55.0, 65.0, 75.0...</td>\n",
       "      <td>[5.613218784332275, 5.597585678100586, 5.57973...</td>\n",
       "      <td>[-1.0, -2.0, -3.0, -4.0, -5.0, -6.0, -7.0, -8....</td>\n",
       "      <td>20160914_145226</td>\n",
       "      <td>CW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CTD_20160924_155359.nc</td>\n",
       "      <td>THETA</td>\n",
       "      <td>73.738861</td>\n",
       "      <td>-61.269279</td>\n",
       "      <td>0.488545</td>\n",
       "      <td>1.404973</td>\n",
       "      <td>0.916428</td>\n",
       "      <td>[8.536798477172852, 8.525147438049316, 3.73222...</td>\n",
       "      <td>[5.0, 15.0, 25.0, 35.0, 45.0, 55.0, 65.0, 75.0...</td>\n",
       "      <td>[3.9821274280548096, 3.950950860977173, 3.9497...</td>\n",
       "      <td>[-1.0, -2.0, -3.0, -4.0, -5.0, -6.0, -7.0, -8....</td>\n",
       "      <td>20160924_155359</td>\n",
       "      <td>NW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2588</th>\n",
       "      <td>CTD_20160923_145953.nc</td>\n",
       "      <td>SALT</td>\n",
       "      <td>81.595177</td>\n",
       "      <td>-64.833717</td>\n",
       "      <td>33.289436</td>\n",
       "      <td>34.247948</td>\n",
       "      <td>0.958511</td>\n",
       "      <td>[30.770662307739258, 30.798933029174805, 31.42...</td>\n",
       "      <td>[5.0, 15.0, 25.0, 35.0, 45.0, 55.0, 65.0, 75.0...</td>\n",
       "      <td>[28.668127059936523, 29.054046630859375, 29.51...</td>\n",
       "      <td>[-1.0, -2.0, -3.0, -4.0, -5.0, -6.0, -7.0, -8....</td>\n",
       "      <td>20160923_145953</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2589</th>\n",
       "      <td>CTD_20160915_155110.nc</td>\n",
       "      <td>SALT</td>\n",
       "      <td>70.899162</td>\n",
       "      <td>-52.730759</td>\n",
       "      <td>33.637035</td>\n",
       "      <td>34.108215</td>\n",
       "      <td>0.471180</td>\n",
       "      <td>[32.13929748535156, 32.14506530761719, 32.4169...</td>\n",
       "      <td>[5.0, 15.0, 25.0, 35.0, 45.0, 55.0, 65.0, 75.0...</td>\n",
       "      <td>[31.12490463256836, 31.138601303100586, 31.339...</td>\n",
       "      <td>[-1.0, -2.0, -3.0, -4.0, -5.0, -6.0, -7.0, -8....</td>\n",
       "      <td>20160915_155110</td>\n",
       "      <td>CW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2590</th>\n",
       "      <td>CTD_20160920_113720.nc</td>\n",
       "      <td>SALT</td>\n",
       "      <td>75.972420</td>\n",
       "      <td>-12.271639</td>\n",
       "      <td>33.287636</td>\n",
       "      <td>34.010475</td>\n",
       "      <td>0.722839</td>\n",
       "      <td>[31.531347274780273, 31.557451248168945, 32.29...</td>\n",
       "      <td>[5.0, 15.0, 25.0, 35.0, 45.0, 55.0, 65.0, 75.0...</td>\n",
       "      <td>[28.721389770507812, 29.012189865112305, 29.05...</td>\n",
       "      <td>[-1.0, -2.0, -3.0, -4.0, -5.0, -6.0, -7.0, -8....</td>\n",
       "      <td>20160920_113720</td>\n",
       "      <td>NE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2591</th>\n",
       "      <td>CTD_20160929_145212.nc</td>\n",
       "      <td>SALT</td>\n",
       "      <td>72.145752</td>\n",
       "      <td>-18.418970</td>\n",
       "      <td>33.823360</td>\n",
       "      <td>34.497578</td>\n",
       "      <td>0.674217</td>\n",
       "      <td>[32.12173080444336, 32.13656234741211, 32.5918...</td>\n",
       "      <td>[5.0, 15.0, 25.0, 35.0, 45.0, 55.0, 65.0, 75.0...</td>\n",
       "      <td>[32.56867599487305, 32.886619567871094, 33.066...</td>\n",
       "      <td>[-1.0, -2.0, -3.0, -4.0, -5.0, -6.0, -7.0, -8....</td>\n",
       "      <td>20160929_145212</td>\n",
       "      <td>NE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2592</th>\n",
       "      <td>CTD_20160914_134856.nc</td>\n",
       "      <td>SALT</td>\n",
       "      <td>71.584473</td>\n",
       "      <td>-58.661140</td>\n",
       "      <td>33.374900</td>\n",
       "      <td>33.913784</td>\n",
       "      <td>0.538883</td>\n",
       "      <td>[31.799428939819336, 31.80912971496582, 32.225...</td>\n",
       "      <td>[5.0, 15.0, 25.0, 35.0, 45.0, 55.0, 65.0, 75.0...</td>\n",
       "      <td>[31.58856964111328, 32.018550872802734, 32.666...</td>\n",
       "      <td>[-1.0, -2.0, -3.0, -4.0, -5.0, -6.0, -7.0, -8....</td>\n",
       "      <td>20160914_134856</td>\n",
       "      <td>CW</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2593 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        file Var_type   latitude  longitude  ecco_mean  \\\n",
       "0     CTD_20160916_140334.nc    THETA  74.732773 -65.246246   0.457267   \n",
       "1     CTD_20160928_154417.nc    THETA  75.957336 -59.610691   1.542009   \n",
       "2     CTD_20160923_153439.nc    THETA  81.222504 -64.780159  -0.851680   \n",
       "3     CTD_20160914_145226.nc    THETA  69.198280 -52.412819   1.602942   \n",
       "4     CTD_20160924_155359.nc    THETA  73.738861 -61.269279   0.488545   \n",
       "...                      ...      ...        ...        ...        ...   \n",
       "2588  CTD_20160923_145953.nc     SALT  81.595177 -64.833717  33.289436   \n",
       "2589  CTD_20160915_155110.nc     SALT  70.899162 -52.730759  33.637035   \n",
       "2590  CTD_20160920_113720.nc     SALT  75.972420 -12.271639  33.287636   \n",
       "2591  CTD_20160929_145212.nc     SALT  72.145752 -18.418970  33.823360   \n",
       "2592  CTD_20160914_134856.nc     SALT  71.584473 -58.661140  33.374900   \n",
       "\n",
       "       omg_mean  difference  \\\n",
       "0      1.256591    0.799324   \n",
       "1      1.341167   -0.200843   \n",
       "2     -0.294011    0.557669   \n",
       "3      2.162872    0.559930   \n",
       "4      1.404973    0.916428   \n",
       "...         ...         ...   \n",
       "2588  34.247948    0.958511   \n",
       "2589  34.108215    0.471180   \n",
       "2590  34.010475    0.722839   \n",
       "2591  34.497578    0.674217   \n",
       "2592  33.913784    0.538883   \n",
       "\n",
       "                                           ecco_profile  \\\n",
       "0     [6.908427715301514, 6.9216132164001465, 3.3188...   \n",
       "1     [2.7182743549346924, 2.717210292816162, 2.4996...   \n",
       "2     [-1.8896114826202393, -1.8808256387710571, -1....   \n",
       "3     [5.706634998321533, 5.755438804626465, 4.86297...   \n",
       "4     [8.536798477172852, 8.525147438049316, 3.73222...   \n",
       "...                                                 ...   \n",
       "2588  [30.770662307739258, 30.798933029174805, 31.42...   \n",
       "2589  [32.13929748535156, 32.14506530761719, 32.4169...   \n",
       "2590  [31.531347274780273, 31.557451248168945, 32.29...   \n",
       "2591  [32.12173080444336, 32.13656234741211, 32.5918...   \n",
       "2592  [31.799428939819336, 31.80912971496582, 32.225...   \n",
       "\n",
       "                                          depth_profile  \\\n",
       "0     [5.0, 15.0, 25.0, 35.0, 45.0, 55.0, 65.0, 75.0...   \n",
       "1                   [5.0, 15.0, 25.0, 35.0, 45.0, 55.0]   \n",
       "2     [5.0, 15.0, 25.0, 35.0, 45.0, 55.0, 65.0, 75.0...   \n",
       "3     [5.0, 15.0, 25.0, 35.0, 45.0, 55.0, 65.0, 75.0...   \n",
       "4     [5.0, 15.0, 25.0, 35.0, 45.0, 55.0, 65.0, 75.0...   \n",
       "...                                                 ...   \n",
       "2588  [5.0, 15.0, 25.0, 35.0, 45.0, 55.0, 65.0, 75.0...   \n",
       "2589  [5.0, 15.0, 25.0, 35.0, 45.0, 55.0, 65.0, 75.0...   \n",
       "2590  [5.0, 15.0, 25.0, 35.0, 45.0, 55.0, 65.0, 75.0...   \n",
       "2591  [5.0, 15.0, 25.0, 35.0, 45.0, 55.0, 65.0, 75.0...   \n",
       "2592  [5.0, 15.0, 25.0, 35.0, 45.0, 55.0, 65.0, 75.0...   \n",
       "\n",
       "                                            omg_profile  \\\n",
       "0     [3.883240222930908, 3.85650897026062, 3.849779...   \n",
       "1     [-0.32447493076324463, -0.3700553774833679, -0...   \n",
       "2     [-1.5689005851745605, -1.5877989530563354, -1....   \n",
       "3     [5.613218784332275, 5.597585678100586, 5.57973...   \n",
       "4     [3.9821274280548096, 3.950950860977173, 3.9497...   \n",
       "...                                                 ...   \n",
       "2588  [28.668127059936523, 29.054046630859375, 29.51...   \n",
       "2589  [31.12490463256836, 31.138601303100586, 31.339...   \n",
       "2590  [28.721389770507812, 29.012189865112305, 29.05...   \n",
       "2591  [32.56867599487305, 32.886619567871094, 33.066...   \n",
       "2592  [31.58856964111328, 32.018550872802734, 32.666...   \n",
       "\n",
       "                                              omg_depth       file_clean  \\\n",
       "0     [-1.0, -2.0, -3.0, -4.0, -5.0, -6.0, -7.0, -8....  20160916_140334   \n",
       "1     [-1.0, -2.0, -3.0, -4.0, -5.0, -6.0, -7.0, -8....  20160928_154417   \n",
       "2     [-1.0, -2.0, -3.0, -4.0, -5.0, -6.0, -7.0, -8....  20160923_153439   \n",
       "3     [-1.0, -2.0, -3.0, -4.0, -5.0, -6.0, -7.0, -8....  20160914_145226   \n",
       "4     [-1.0, -2.0, -3.0, -4.0, -5.0, -6.0, -7.0, -8....  20160924_155359   \n",
       "...                                                 ...              ...   \n",
       "2588  [-1.0, -2.0, -3.0, -4.0, -5.0, -6.0, -7.0, -8....  20160923_145953   \n",
       "2589  [-1.0, -2.0, -3.0, -4.0, -5.0, -6.0, -7.0, -8....  20160915_155110   \n",
       "2590  [-1.0, -2.0, -3.0, -4.0, -5.0, -6.0, -7.0, -8....  20160920_113720   \n",
       "2591  [-1.0, -2.0, -3.0, -4.0, -5.0, -6.0, -7.0, -8....  20160929_145212   \n",
       "2592  [-1.0, -2.0, -3.0, -4.0, -5.0, -6.0, -7.0, -8....  20160914_134856   \n",
       "\n",
       "     Region  \n",
       "0        NW  \n",
       "1        NW  \n",
       "2         N  \n",
       "3        CW  \n",
       "4        NW  \n",
       "...     ...  \n",
       "2588      N  \n",
       "2589     CW  \n",
       "2590     NE  \n",
       "2591     NE  \n",
       "2592     CW  \n",
       "\n",
       "[2593 rows x 13 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecco_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba88c958-b755-4b9e-9f6b-1a667bb20b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASTE\n",
    "aste_csv = pd.read_csv(\"/Users/sherine_aldrin/Downloads/CoOL/ASTE_Greenland_Model/full_profiles_with_region.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46e21ddb-4a71-4c13-b698-3f6df40d15fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#aste_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ab10b6fc-5831-4b6d-9efa-fba7db2a2151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ORAS5\n",
    "oras5_salt_csv = \"/Users/sherine_aldrin/Downloads/CoOL/ORAS5/Salt_ORAS5_Profiles.csv\"\n",
    "oras5_temp_csv = \"/Users/sherine_aldrin/Downloads/CoOL/ORAS5/Temp_ORAS5_Profiles.csv\"\n",
    "\n",
    "oras5_paths = [oras5_salt_csv, oras5_temp_csv]\n",
    "\n",
    "# Combine all CSVs\n",
    "o_summary_df_list = [pd.read_csv(csv) for csv in oras5_paths]\n",
    "oras5_csv = pd.concat(o_summary_df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "08f414e7-daef-4136-86b5-4704a5496f5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CTD_file</th>\n",
       "      <th>Var_type</th>\n",
       "      <th>ORAS5 lon(X)</th>\n",
       "      <th>ORAS5 lat(Y)</th>\n",
       "      <th>OMG lon(X)</th>\n",
       "      <th>OMG lat(Y)</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>depth_profile</th>\n",
       "      <th>omg_depth</th>\n",
       "      <th>Profile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CTD_20171018_140759.nc</td>\n",
       "      <td>Salinity</td>\n",
       "      <td>-57.366630</td>\n",
       "      <td>73.779686</td>\n",
       "      <td>-57.244930</td>\n",
       "      <td>73.826927</td>\n",
       "      <td>6.468833</td>\n",
       "      <td>2017</td>\n",
       "      <td>10</td>\n",
       "      <td>[0.5057600140571594, 1.5558552742004395, 2.667...</td>\n",
       "      <td>[1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, ...</td>\n",
       "      <td>[32.70927810668945, 32.70988082885742, 32.7103...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CTD_20171015_121330.nc</td>\n",
       "      <td>Salinity</td>\n",
       "      <td>-23.249292</td>\n",
       "      <td>69.402310</td>\n",
       "      <td>-23.205521</td>\n",
       "      <td>69.445000</td>\n",
       "      <td>5.045602</td>\n",
       "      <td>2017</td>\n",
       "      <td>10</td>\n",
       "      <td>[0.5057600140571594, 1.5558552742004395, 2.667...</td>\n",
       "      <td>[1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, ...</td>\n",
       "      <td>[32.69133377075195, 32.69158172607422, 32.6917...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CTD_20171023_131753.nc</td>\n",
       "      <td>Salinity</td>\n",
       "      <td>-56.004517</td>\n",
       "      <td>65.608215</td>\n",
       "      <td>-55.850670</td>\n",
       "      <td>65.594276</td>\n",
       "      <td>7.234636</td>\n",
       "      <td>2017</td>\n",
       "      <td>10</td>\n",
       "      <td>[0.5057600140571594, 1.5558552742004395, 2.667...</td>\n",
       "      <td>[1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, ...</td>\n",
       "      <td>[34.30541229248047, 34.30556869506836, 34.3056...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CTD_20171014_094217.nc</td>\n",
       "      <td>Salinity</td>\n",
       "      <td>-31.717012</td>\n",
       "      <td>65.778570</td>\n",
       "      <td>-31.637300</td>\n",
       "      <td>65.822403</td>\n",
       "      <td>6.078883</td>\n",
       "      <td>2017</td>\n",
       "      <td>10</td>\n",
       "      <td>[0.5057600140571594, 1.5558552742004395, 2.667...</td>\n",
       "      <td>[1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, ...</td>\n",
       "      <td>[34.77607345581055, 34.77607345581055, 34.7760...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CTD_20171018_132130.nc</td>\n",
       "      <td>Salinity</td>\n",
       "      <td>-58.078846</td>\n",
       "      <td>74.363525</td>\n",
       "      <td>-57.999519</td>\n",
       "      <td>74.337631</td>\n",
       "      <td>3.735127</td>\n",
       "      <td>2017</td>\n",
       "      <td>10</td>\n",
       "      <td>[0.5057600140571594, 1.5558552742004395, 2.667...</td>\n",
       "      <td>[1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, ...</td>\n",
       "      <td>[32.57299041748047, 32.573184967041016, 32.573...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>CTD_20171018_145516.nc</td>\n",
       "      <td>Theta</td>\n",
       "      <td>-62.996426</td>\n",
       "      <td>74.244980</td>\n",
       "      <td>-63.013149</td>\n",
       "      <td>74.217323</td>\n",
       "      <td>3.116375</td>\n",
       "      <td>2017</td>\n",
       "      <td>10</td>\n",
       "      <td>[0.5057600140571594, 1.5558552742004395, 2.667...</td>\n",
       "      <td>[1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, ...</td>\n",
       "      <td>[-0.27659329771995544, -0.2763379216194153, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>CTD_20171015_100856.nc</td>\n",
       "      <td>Theta</td>\n",
       "      <td>-32.709553</td>\n",
       "      <td>67.437960</td>\n",
       "      <td>-32.772701</td>\n",
       "      <td>67.481682</td>\n",
       "      <td>5.557531</td>\n",
       "      <td>2017</td>\n",
       "      <td>10</td>\n",
       "      <td>[0.5057600140571594, 1.5558552742004395, 2.667...</td>\n",
       "      <td>[1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, ...</td>\n",
       "      <td>[1.177574634552002, 1.1860132217407227, 1.1970...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>CTD_20171015_152820.nc</td>\n",
       "      <td>Theta</td>\n",
       "      <td>-27.627980</td>\n",
       "      <td>66.857160</td>\n",
       "      <td>-27.664829</td>\n",
       "      <td>66.834633</td>\n",
       "      <td>2.978867</td>\n",
       "      <td>2017</td>\n",
       "      <td>10</td>\n",
       "      <td>[0.5057600140571594, 1.5558552742004395, 2.667...</td>\n",
       "      <td>[1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, ...</td>\n",
       "      <td>[2.3828439712524414, 2.3829753398895264, 2.383...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>CTD_20171018_170019.nc</td>\n",
       "      <td>Theta</td>\n",
       "      <td>-68.288390</td>\n",
       "      <td>75.377250</td>\n",
       "      <td>-68.266647</td>\n",
       "      <td>75.407066</td>\n",
       "      <td>3.370737</td>\n",
       "      <td>2017</td>\n",
       "      <td>10</td>\n",
       "      <td>[0.5057600140571594, 1.5558552742004395, 2.667...</td>\n",
       "      <td>[1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, ...</td>\n",
       "      <td>[-0.6451374292373657, -0.6447781920433044, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>CTD_20171023_153140.nc</td>\n",
       "      <td>Theta</td>\n",
       "      <td>-53.726948</td>\n",
       "      <td>70.890350</td>\n",
       "      <td>-53.677380</td>\n",
       "      <td>70.908783</td>\n",
       "      <td>2.730302</td>\n",
       "      <td>2017</td>\n",
       "      <td>10</td>\n",
       "      <td>[0.5057600140571594, 1.5558552742004395, 2.667...</td>\n",
       "      <td>[1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, ...</td>\n",
       "      <td>[1.653062343597412, 1.659035563468933, 1.66111...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>722 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   CTD_file  Var_type  ORAS5 lon(X)  ORAS5 lat(Y)  OMG lon(X)  \\\n",
       "0    CTD_20171018_140759.nc  Salinity    -57.366630     73.779686  -57.244930   \n",
       "1    CTD_20171015_121330.nc  Salinity    -23.249292     69.402310  -23.205521   \n",
       "2    CTD_20171023_131753.nc  Salinity    -56.004517     65.608215  -55.850670   \n",
       "3    CTD_20171014_094217.nc  Salinity    -31.717012     65.778570  -31.637300   \n",
       "4    CTD_20171018_132130.nc  Salinity    -58.078846     74.363525  -57.999519   \n",
       "..                      ...       ...           ...           ...         ...   \n",
       "717  CTD_20171018_145516.nc     Theta    -62.996426     74.244980  -63.013149   \n",
       "718  CTD_20171015_100856.nc     Theta    -32.709553     67.437960  -32.772701   \n",
       "719  CTD_20171015_152820.nc     Theta    -27.627980     66.857160  -27.664829   \n",
       "720  CTD_20171018_170019.nc     Theta    -68.288390     75.377250  -68.266647   \n",
       "721  CTD_20171023_153140.nc     Theta    -53.726948     70.890350  -53.677380   \n",
       "\n",
       "     OMG lat(Y)  Distance  Year  Month  \\\n",
       "0     73.826927  6.468833  2017     10   \n",
       "1     69.445000  5.045602  2017     10   \n",
       "2     65.594276  7.234636  2017     10   \n",
       "3     65.822403  6.078883  2017     10   \n",
       "4     74.337631  3.735127  2017     10   \n",
       "..          ...       ...   ...    ...   \n",
       "717   74.217323  3.116375  2017     10   \n",
       "718   67.481682  5.557531  2017     10   \n",
       "719   66.834633  2.978867  2017     10   \n",
       "720   75.407066  3.370737  2017     10   \n",
       "721   70.908783  2.730302  2017     10   \n",
       "\n",
       "                                         depth_profile  \\\n",
       "0    [0.5057600140571594, 1.5558552742004395, 2.667...   \n",
       "1    [0.5057600140571594, 1.5558552742004395, 2.667...   \n",
       "2    [0.5057600140571594, 1.5558552742004395, 2.667...   \n",
       "3    [0.5057600140571594, 1.5558552742004395, 2.667...   \n",
       "4    [0.5057600140571594, 1.5558552742004395, 2.667...   \n",
       "..                                                 ...   \n",
       "717  [0.5057600140571594, 1.5558552742004395, 2.667...   \n",
       "718  [0.5057600140571594, 1.5558552742004395, 2.667...   \n",
       "719  [0.5057600140571594, 1.5558552742004395, 2.667...   \n",
       "720  [0.5057600140571594, 1.5558552742004395, 2.667...   \n",
       "721  [0.5057600140571594, 1.5558552742004395, 2.667...   \n",
       "\n",
       "                                             omg_depth  \\\n",
       "0    [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, ...   \n",
       "1    [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, ...   \n",
       "2    [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, ...   \n",
       "3    [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, ...   \n",
       "4    [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, ...   \n",
       "..                                                 ...   \n",
       "717  [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, ...   \n",
       "718  [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, ...   \n",
       "719  [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, ...   \n",
       "720  [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, ...   \n",
       "721  [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, ...   \n",
       "\n",
       "                                               Profile  \n",
       "0    [32.70927810668945, 32.70988082885742, 32.7103...  \n",
       "1    [32.69133377075195, 32.69158172607422, 32.6917...  \n",
       "2    [34.30541229248047, 34.30556869506836, 34.3056...  \n",
       "3    [34.77607345581055, 34.77607345581055, 34.7760...  \n",
       "4    [32.57299041748047, 32.573184967041016, 32.573...  \n",
       "..                                                 ...  \n",
       "717  [-0.27659329771995544, -0.2763379216194153, -0...  \n",
       "718  [1.177574634552002, 1.1860132217407227, 1.1970...  \n",
       "719  [2.3828439712524414, 2.3829753398895264, 2.383...  \n",
       "720  [-0.6451374292373657, -0.6447781920433044, -0....  \n",
       "721  [1.653062343597412, 1.659035563468933, 1.66111...  \n",
       "\n",
       "[722 rows x 12 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oras5_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2105f34-7398-48b7-91f4-d909a201a0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLORYS\n",
    "\n",
    "glorys_salt_data = \"/Users/sherine_aldrin/Downloads/CoOL/GLORYS/Salt_GLORYS_Profiles.csv\"\n",
    "glorys_temp_data = \"/Users/sherine_aldrin/Downloads/CoOL/GLORYS/Temp_GLORYS_Profiles.csv\"\n",
    "\n",
    "glorys_paths = [glorys_salt_data, glorys_temp_data]\n",
    "g_summary_df_list = [pd.read_csv(csv) for csv in glorys_paths]\n",
    "glorys_csv = pd.concat(g_summary_df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11926504-46e5-45da-947f-0e625133beea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#glorys_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b493af4b-9e98-4760-92cb-760a54eb21eb",
   "metadata": {},
   "source": [
    "#### Important variables!\n",
    "\n",
    "ECCO = ecco mean, omg mean\n",
    "ASTE = ??\n",
    "ORAS5 = ??\n",
    "GLORYS = ??\n",
    "\n",
    "\n",
    "Now I realize I may have not trimmed all the nan's or 0's. I think ecco is good, but double check the other three..\n",
    "OK all three have the profiles, I think the mean would just be using the mean function but MAKING sure to remove the nan or 0 values..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b2c06924-6a25-44e3-a604-8cdc5f9828f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.DataFrame({'Name': ['Alice', 'Bob'], 'Age': [25, 30]})\n",
    "#omg_headers = pd.DataFrame({'omg': omg_csv.columns.tolist()})\n",
    "ecco_headers = pd.DataFrame({'ecco': ecco_csv.columns.tolist()})\n",
    "aste_headers = pd.DataFrame({'aste': aste_csv.columns.tolist()})\n",
    "oras5_headers = pd.DataFrame({'oras5':oras5_csv.columns.tolist()})\n",
    "glorys_headers = pd.DataFrame({'glorys':glorys_csv.columns.tolist()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "34ff32e5-6dcc-4a1c-92d3-3ba2ee7e33d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ecco</th>\n",
       "      <th>aste</th>\n",
       "      <th>oras5</th>\n",
       "      <th>glorys</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>file</td>\n",
       "      <td>CTD_file</td>\n",
       "      <td>CTD_file</td>\n",
       "      <td>CTD_file</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Var_type</td>\n",
       "      <td>Year</td>\n",
       "      <td>Var_type</td>\n",
       "      <td>Var_type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>latitude</td>\n",
       "      <td>Month</td>\n",
       "      <td>ORAS5 lon(X)</td>\n",
       "      <td>GLORYS lon(X)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>longitude</td>\n",
       "      <td>ASTE_tile</td>\n",
       "      <td>ORAS5 lat(Y)</td>\n",
       "      <td>GLORYS lat(Y)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ecco_mean</td>\n",
       "      <td>ASTE_lat</td>\n",
       "      <td>OMG lon(X)</td>\n",
       "      <td>OMG lon(X)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>omg_mean</td>\n",
       "      <td>Distance</td>\n",
       "      <td>OMG lat(Y)</td>\n",
       "      <td>OMG lat(Y)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>difference</td>\n",
       "      <td>ASTE_lon</td>\n",
       "      <td>Distance</td>\n",
       "      <td>Distance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ecco_profile</td>\n",
       "      <td>Var_type</td>\n",
       "      <td>Year</td>\n",
       "      <td>Year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>depth_profile</td>\n",
       "      <td>depth_profile_x</td>\n",
       "      <td>Month</td>\n",
       "      <td>Month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>omg_profile</td>\n",
       "      <td>omg_depth_x</td>\n",
       "      <td>depth_profile</td>\n",
       "      <td>depth_profile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>omg_depth</td>\n",
       "      <td>Profile</td>\n",
       "      <td>omg_depth</td>\n",
       "      <td>omg_depth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>file_clean</td>\n",
       "      <td>depth_profile_y</td>\n",
       "      <td>Profile</td>\n",
       "      <td>Profile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Region</td>\n",
       "      <td>omg_depth_y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ASTE_year</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ASTE_month</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Region</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ecco             aste          oras5         glorys\n",
       "0            file         CTD_file       CTD_file       CTD_file\n",
       "1        Var_type             Year       Var_type       Var_type\n",
       "2        latitude            Month   ORAS5 lon(X)  GLORYS lon(X)\n",
       "3       longitude        ASTE_tile   ORAS5 lat(Y)  GLORYS lat(Y)\n",
       "4       ecco_mean         ASTE_lat     OMG lon(X)     OMG lon(X)\n",
       "5        omg_mean         Distance     OMG lat(Y)     OMG lat(Y)\n",
       "6      difference         ASTE_lon       Distance       Distance\n",
       "7    ecco_profile         Var_type           Year           Year\n",
       "8   depth_profile  depth_profile_x          Month          Month\n",
       "9     omg_profile      omg_depth_x  depth_profile  depth_profile\n",
       "10      omg_depth          Profile      omg_depth      omg_depth\n",
       "11     file_clean  depth_profile_y        Profile        Profile\n",
       "12         Region      omg_depth_y            NaN            NaN\n",
       "13            NaN        ASTE_year            NaN            NaN\n",
       "14            NaN       ASTE_month            NaN            NaN\n",
       "15            NaN           Region            NaN            NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_headers = pd.concat([ecco_headers, aste_headers, oras5_headers, glorys_headers], axis=1)\n",
    "display(all_headers) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2bdf39c-fd23-4fab-b73e-615fe9bfefec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OMG Over here I need to make sure I get all the OMG profiles!\n",
    "\n",
    "def get_all_nc_files(folder):\n",
    "    nc_files = []\n",
    "    for root, dirs, files in os.walk(folder):\n",
    "        for file in files:\n",
    "            if file.endswith(\".nc\"):\n",
    "                nc_files.append(os.path.join(root, file))\n",
    "                #nc_files.append(file)\n",
    "    return nc_files\n",
    "\n",
    "\n",
    "#omg_csv = pd.read_csv(\"/Users/sherine_aldrin/Downloads/CoOL/ORAS5/OMG_CTD_Locations_2016_2017_with_region.csv\") Originally have this, \n",
    "#but I don't want to ruin it so I might just make a new csv or dataframe just with the profile stuff\n",
    "#so that I can access just that when finding the differences with all the other models\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## THIS LOOP!! want to make a function so that I can easily make a dataframe for each model\n",
    "## the output should be a csv with the profiles, the region, the data, and the mean differences\n",
    "\n",
    "omg_paths = get_all_nc_files(\"/Users/sherine_aldrin/Downloads/CoOL/Comparing_Models/OMG_data\")\n",
    "omg_locs = get_all_nc_files(\"/Users/sherine_aldrin/Downloads/CoOL/Comparing_Models/OMG_CTD_Locations_2016_2017_with_region\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2d1cd513-ecbe-4e85-814f-7975a1745d22",
   "metadata": {},
   "source": [
    "def findDiffs(model_csv, output_name):\n",
    "    summary_rows = []\n",
    "    for file in omg_paths:\n",
    "        omg_csv = pd.read_csv(file)\n",
    "        profile_mean = np.nanmean() \n",
    "    summary_rows.append({\n",
    "            \"file\": os.path.basename(omg_file),\n",
    "            \"omg_mean\": np.nanmean(model_csv[,\n",
    "            \"omg_mean\": omg_mean,\n",
    "            \"difference\": diff\n",
    "        })\n",
    "\n",
    "    # Save to CSV\n",
    "    with open(\"Temp_GLORYS_Profiles.csv\", \"w\", newline=\"\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=[\"CTD_file\", \"Var_type\", \"GLORYS lon(X)\", \"GLORYS lat(Y)\", \"OMG lon(X)\", \"OMG lat(Y)\", \"Distance\", \"Year\", \"Month\", \"Profile\"])\n",
    "        writer.writeheader()\n",
    "        writer.writerows(temp_summary_rows)\n",
    "\n",
    "    print(\"Saved: ALL GLORYS_Temp_Profiles.csv\")\n",
    "\n",
    "    with open(\"Salt_GLORYS_Profiles.csv\", \"w\", newline=\"\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=[\"CTD_file\", \"Var_type\", \"GLORYS lon(X)\", \"GLORYS lat(Y)\", \"OMG lon(X)\", \"OMG lat(Y)\", \"Distance\", \"Year\", \"Month\", \"Profile\"])\n",
    "        writer.writeheader()\n",
    "        writer.writerows(salt_summary_rows)\n",
    "\n",
    "    print(\"Saved: ALL GLORYS_Salt_Profiles.csv\")\n",
    "\n",
    "\n",
    "## 3:52 on Wednesday = realizing I need to find the means of the profiles with the following function:\n",
    "np.nanmean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedd2ecd-5c71-4723-b17d-0f1e55587314",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3343766c-5067-446c-a5d0-bd0c56bfd3a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef findDiffs(model_csv, output_name, var_type_name, is_ecco=False):\\n    omg_paths = get_all_nc_files(\"/Users/sherine_aldrin/Downloads/CoOL/Comparing_Models/OMG_data\")\\n    region_info = pd.read_csv(\"/Users/sherine_aldrin/Downloads/CoOL/Comparing_Models/OMG_CTD_Locations_2016_2017_with_region.csv\")\\n\\n    df = model_csv\\n\\n    # Try to detect the CTD file column\\n    possible_ctd_cols = [\"CTD_file\", \"file\", \"File_ID\"]\\n    for col in possible_ctd_cols:\\n        if col in df.columns:\\n            df[\"CTD_file\"] = df[col]\\n            break\\n    if \"CTD_file\" not in df.columns:\\n        raise ValueError(\"Could not find CTD file column in input CSV\")\\n\\n    # Get File_ID for matching with region info\\n    df[\"File_ID\"] = df[\"CTD_file\"].astype(str).str.replace(\"CTD_\", \"\", regex=False).str.replace(\".nc\", \"\", regex=False)\\n\\n    \\n    # Add region info\\n    if \"Region\" in df.columns:\\n        df[\"Region\"] = df[\"Region\"].fillna(\"Unassigned\")\\n    else:\\n        df = df.merge(region_info[[\"File_ID\", \"Region\"]], on=\"File_ID\", how=\"left\")\\n        df[\"Region\"] = df[\"Region\"].fillna(\"Unassigned\")\\n\\n    # Clean up profile\\n    # Pick profile column dynamically based on var_type\\n    \\n    else:\\n        # ASTE / ORAS5 / GLORYS\\n        if var_type.upper() in [\"THETA\", \"TEMPERATURE\"]:\\n            profile_col = \"Profile_temp\" if \"Profile_temp\" in row else \"Profile\"\\n        elif var_type.upper() in [\"SALT\", \"SALINITY\"]:\\n            profile_col = \"Profile_salt\" if \"Profile_salt\" in row else \"Profile\"\\n        else:\\n            print(f\"Unknown var_type in model_csv: {var_type}\")\\n            continue\\n        profile = np.array(row[profile_col])\\n\\n\\n    summary_rows = []\\n    for _, row in df.iterrows():\\n        ctd_file = row[\"CTD_file\"]\\n        region = row[\"Region\"]\\n        \\n        if is_ecco:\\n        # ECCO data\\n        if var_type.upper() in [\"THETA\", \"TEMPERATURE\"]:\\n            profile_col = \"ecco_profile_temp\" if \"ecco_profile_temp\" in row else \"ecco_profile\"\\n        elif var_type.upper() in [\"SALT\", \"SALINITY\"]:\\n            profile_col = \"ecco_profile_salt\" if \"ecco_profile_salt\" in row else \"ecco_profile\"\\n        else:\\n            print(f\"Unknown var_type in ECCO: {var_type}\")\\n            continue\\n        profile = np.array(row[profile_col])\\n        \\n        #if is_ecco:\\n         #   profile = np.array(row[\"ecco_profile\"])\\n        #else:\\n         #   profile = np.array(row[\"Profile\"])\\n\\n        #if len(profile) == 0:\\n          #  continue\\n\\n        # Detect variable type\\n        var_type = row[\"Var_type\"] if \"Var_type\" in row and pd.notna(row[\"Var_type\"]) else var_type_name\\n        # Normalize ASTE-style codes to standard names\\n        if var_type.upper() == \"THETA\":\\n            var_type = \"Theta\"\\n        elif var_type.upper() == \"SALT\":\\n            var_type = \"Salinity\"\\n\\n        if var_type is None:\\n            raise ValueError(\"Could not determine variable type\")\\n\\n        # Match to CTD NetCDF path\\n        #match_path = [p for p in omg_paths if os.path.basename(p) == ctd_file] #not working for aste data\\n        match_path = [p for p in omg_paths if ctd_file in os.path.basename(p)]\\n        if not match_path:\\n            print(\"NO MATCH:\", ctd_file)\\n            continue\\n        ctd_path = match_path[0]\\n\\n        ctd_depths, ctd_values = read_ctd_profile(ctd_path, var_type)\\n        if (\\n            ctd_values is None or len(ctd_values) == 0 or\\n            ctd_depths is None or len(ctd_depths) == 0\\n        ):\\n            continue\\n\\n        # Interpolate both to same depth scale\\n        interp_len = min(len(profile), len(ctd_values))\\n        common_depths = np.linspace(ctd_depths.min(), ctd_depths.max(), interp_len)\\n        ctd_interp = np.interp(common_depths, ctd_depths, ctd_values)\\n        model_interp = np.interp(common_depths,\\n                                 np.linspace(ctd_depths.min(), ctd_depths.max(), len(profile)),\\n                                 profile)\\n\\n        diff = model_interp - ctd_interp\\n        mean_diff = np.nanmean(diff)\\n\\n        summary_rows.append({\\n            \"CTD_file\": ctd_file,\\n            \"File_ID\": row[\"File_ID\"],\\n            \"Var_type\": var_type,\\n            \"Region\": region,\\n            \"OMG_Mean\": np.nanmean(ctd_interp),\\n            \"Model_Mean\": np.nanmean(model_interp),\\n            \"Difference\": mean_diff,\\n            \"Model_Profile\": profile.tolist(),\\n            \"depth_profile\": clean_profile(row[\"depth_profile\"]),\\n            \"omg_depth\": clean_profile(row[\"omg_depth\"]),\\n            \"Profile_Diff\": diff.tolist()\\n        })\\n\\n    summary_df = pd.DataFrame(summary_rows)\\n    summary_df.to_csv(output_name, index=False)\\n    print(f\"Saved summary to: {output_name}\")\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#def clean_profile(profile_string):\n",
    "   # if pd.isna(profile_string):\n",
    "      # return []\n",
    "    #nums = re.findall(r'[-+]?[\\d]*\\.?[\\d]+', profile_string)\n",
    "   # return [float(x) for x in nums if float(x) != 0.0]\n",
    "\n",
    "def clean_profile(profile_data):\n",
    "    if profile_data is None:\n",
    "        return []\n",
    "    if isinstance(profile_data, (list, np.ndarray)):\n",
    "        return [float(x) for x in profile_data if float(x) != 0.0 and not np.isnan(x)]\n",
    "    if isinstance(profile_data, str):\n",
    "        nums = re.findall(r'[-+]?\\d*\\.\\d+|\\d+', profile_data)\n",
    "        return [float(x) for x in nums if float(x) != 0.0]\n",
    "    return []\n",
    "\n",
    "\n",
    "def read_ctd_profile(path, var_type):\n",
    "    try:\n",
    "        ds = xr.open_dataset(path)\n",
    "        if var_type == \"Theta\":\n",
    "            values = ds[\"potential_temperature\"].values\n",
    "        elif var_type == \"Salinity\":\n",
    "            values = ds[\"practical_salinity\"].values\n",
    "        else:\n",
    "            return None, None\n",
    "        depths = ds[\"depth\"].values\n",
    "        ds.close()\n",
    "        return depths, values\n",
    "    except Exception as e:\n",
    "        print(f\"Failed reading CTD file {path}: {e}\")\n",
    "        return None, None\n",
    "\n",
    "'''\n",
    "def findDiffs(model_csv, output_name, var_type_name, is_ecco=False):\n",
    "    omg_paths = get_all_nc_files(\"/Users/sherine_aldrin/Downloads/CoOL/Comparing_Models/OMG_data\")\n",
    "    region_info = pd.read_csv(\"/Users/sherine_aldrin/Downloads/CoOL/Comparing_Models/OMG_CTD_Locations_2016_2017_with_region.csv\")\n",
    "\n",
    "    df = model_csv\n",
    "\n",
    "    # Try to detect the CTD file column\n",
    "    possible_ctd_cols = [\"CTD_file\", \"file\", \"File_ID\"]\n",
    "    for col in possible_ctd_cols:\n",
    "        if col in df.columns:\n",
    "            df[\"CTD_file\"] = df[col]\n",
    "            break\n",
    "    if \"CTD_file\" not in df.columns:\n",
    "        raise ValueError(\"Could not find CTD file column in input CSV\")\n",
    "\n",
    "    # Get File_ID for matching with region info\n",
    "    df[\"File_ID\"] = df[\"CTD_file\"].astype(str).str.replace(\"CTD_\", \"\", regex=False).str.replace(\".nc\", \"\", regex=False)\n",
    "\n",
    "    \n",
    "    # Add region info\n",
    "    if \"Region\" in df.columns:\n",
    "        df[\"Region\"] = df[\"Region\"].fillna(\"Unassigned\")\n",
    "    else:\n",
    "        df = df.merge(region_info[[\"File_ID\", \"Region\"]], on=\"File_ID\", how=\"left\")\n",
    "        df[\"Region\"] = df[\"Region\"].fillna(\"Unassigned\")\n",
    "\n",
    "    # Clean up profile\n",
    "    # Pick profile column dynamically based on var_type\n",
    "    \n",
    "    else:\n",
    "        # ASTE / ORAS5 / GLORYS\n",
    "        if var_type.upper() in [\"THETA\", \"TEMPERATURE\"]:\n",
    "            profile_col = \"Profile_temp\" if \"Profile_temp\" in row else \"Profile\"\n",
    "        elif var_type.upper() in [\"SALT\", \"SALINITY\"]:\n",
    "            profile_col = \"Profile_salt\" if \"Profile_salt\" in row else \"Profile\"\n",
    "        else:\n",
    "            print(f\"Unknown var_type in model_csv: {var_type}\")\n",
    "            continue\n",
    "        profile = np.array(row[profile_col])\n",
    "\n",
    "\n",
    "    summary_rows = []\n",
    "    for _, row in df.iterrows():\n",
    "        ctd_file = row[\"CTD_file\"]\n",
    "        region = row[\"Region\"]\n",
    "        \n",
    "        if is_ecco:\n",
    "        # ECCO data\n",
    "        if var_type.upper() in [\"THETA\", \"TEMPERATURE\"]:\n",
    "            profile_col = \"ecco_profile_temp\" if \"ecco_profile_temp\" in row else \"ecco_profile\"\n",
    "        elif var_type.upper() in [\"SALT\", \"SALINITY\"]:\n",
    "            profile_col = \"ecco_profile_salt\" if \"ecco_profile_salt\" in row else \"ecco_profile\"\n",
    "        else:\n",
    "            print(f\"Unknown var_type in ECCO: {var_type}\")\n",
    "            continue\n",
    "        profile = np.array(row[profile_col])\n",
    "        \n",
    "        #if is_ecco:\n",
    "         #   profile = np.array(row[\"ecco_profile\"])\n",
    "        #else:\n",
    "         #   profile = np.array(row[\"Profile\"])\n",
    "\n",
    "        #if len(profile) == 0:\n",
    "          #  continue\n",
    "\n",
    "        # Detect variable type\n",
    "        var_type = row[\"Var_type\"] if \"Var_type\" in row and pd.notna(row[\"Var_type\"]) else var_type_name\n",
    "        # Normalize ASTE-style codes to standard names\n",
    "        if var_type.upper() == \"THETA\":\n",
    "            var_type = \"Theta\"\n",
    "        elif var_type.upper() == \"SALT\":\n",
    "            var_type = \"Salinity\"\n",
    "\n",
    "        if var_type is None:\n",
    "            raise ValueError(\"Could not determine variable type\")\n",
    "\n",
    "        # Match to CTD NetCDF path\n",
    "        #match_path = [p for p in omg_paths if os.path.basename(p) == ctd_file] #not working for aste data\n",
    "        match_path = [p for p in omg_paths if ctd_file in os.path.basename(p)]\n",
    "        if not match_path:\n",
    "            print(\"NO MATCH:\", ctd_file)\n",
    "            continue\n",
    "        ctd_path = match_path[0]\n",
    "\n",
    "        ctd_depths, ctd_values = read_ctd_profile(ctd_path, var_type)\n",
    "        if (\n",
    "            ctd_values is None or len(ctd_values) == 0 or\n",
    "            ctd_depths is None or len(ctd_depths) == 0\n",
    "        ):\n",
    "            continue\n",
    "\n",
    "        # Interpolate both to same depth scale\n",
    "        interp_len = min(len(profile), len(ctd_values))\n",
    "        common_depths = np.linspace(ctd_depths.min(), ctd_depths.max(), interp_len)\n",
    "        ctd_interp = np.interp(common_depths, ctd_depths, ctd_values)\n",
    "        model_interp = np.interp(common_depths,\n",
    "                                 np.linspace(ctd_depths.min(), ctd_depths.max(), len(profile)),\n",
    "                                 profile)\n",
    "\n",
    "        diff = model_interp - ctd_interp\n",
    "        mean_diff = np.nanmean(diff)\n",
    "\n",
    "        summary_rows.append({\n",
    "            \"CTD_file\": ctd_file,\n",
    "            \"File_ID\": row[\"File_ID\"],\n",
    "            \"Var_type\": var_type,\n",
    "            \"Region\": region,\n",
    "            \"OMG_Mean\": np.nanmean(ctd_interp),\n",
    "            \"Model_Mean\": np.nanmean(model_interp),\n",
    "            \"Difference\": mean_diff,\n",
    "            \"Model_Profile\": profile.tolist(),\n",
    "            \"depth_profile\": clean_profile(row[\"depth_profile\"]),\n",
    "            \"omg_depth\": clean_profile(row[\"omg_depth\"]),\n",
    "            \"Profile_Diff\": diff.tolist()\n",
    "        })\n",
    "\n",
    "    summary_df = pd.DataFrame(summary_rows)\n",
    "    summary_df.to_csv(output_name, index=False)\n",
    "    print(f\"Saved summary to: {output_name}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "raw",
   "id": "92981e61-a310-4ba5-8de8-1ec0220e0e22",
   "metadata": {},
   "source": [
    "def findDiffs(model_csv, output_name, var_type_name, is_ecco=False):\n",
    "    omg_paths = get_all_nc_files(\"/Users/sherine_aldrin/Downloads/CoOL/Comparing_Models/OMG_data\")\n",
    "    region_info = pd.read_csv(\"/Users/sherine_aldrin/Downloads/CoOL/Comparing_Models/OMG_CTD_Locations_2016_2017_with_region.csv\")\n",
    "\n",
    "    # work on a copy\n",
    "    df = model_csv.copy()\n",
    "\n",
    "    # Detect CTD_file column\n",
    "    possible_ctd_cols = [\"CTD_file\", \"file\", \"File_ID\"]\n",
    "    for col in possible_ctd_cols:\n",
    "        if col in df.columns:\n",
    "            df[\"CTD_file\"] = df[col]\n",
    "            break\n",
    "    if \"CTD_file\" not in df.columns:\n",
    "        raise ValueError(\"Could not find CTD file column in input CSV\")\n",
    "\n",
    "    # Derive File_ID and merge Region\n",
    "    df[\"File_ID\"] = (\n",
    "        df[\"CTD_file\"]\n",
    "        .astype(str)\n",
    "        .str.replace(\"CTD_\", \"\", regex=False)\n",
    "        .str.replace(\".nc\", \"\", regex=False)\n",
    "    )\n",
    "\n",
    "    if \"Region\" not in df.columns:\n",
    "        df = df.merge(region_info[[\"File_ID\", \"Region\"]], on=\"File_ID\", how=\"left\")\n",
    "    df[\"Region\"] = df[\"Region\"].fillna(\"Unassigned\")\n",
    "\n",
    "    summary_rows = []\n",
    "\n",
    "    # Loop through each row\n",
    "    for _, row in df.iterrows():\n",
    "        # Determine variable type\n",
    "        var_type = row[\"Var_type\"] if \"Var_type\" in row and pd.notna(row[\"Var_type\"]) else var_type_name\n",
    "        if var_type.upper() in [\"THETA\", \"TEMPERATURE\"]:\n",
    "            normalized_type = \"Theta\"\n",
    "        elif var_type.upper() in [\"SALT\", \"SALINITY\"]:\n",
    "            normalized_type = \"Salinity\"\n",
    "        else:\n",
    "            print(f\"Skipping unknown Var_type: {var_type}\")\n",
    "            continue\n",
    "\n",
    "        # Pick profile column\n",
    "        if is_ecco:\n",
    "            if normalized_type == \"Theta\":\n",
    "                profile_col = \"ecco_profile_temp\" if \"ecco_profile_temp\" in row else (\n",
    "                    \"ecco_profile\" if \"ecco_profile\" in row else None)\n",
    "            else:\n",
    "                profile_col = \"ecco_profile_salt\" if \"ecco_profile_salt\" in row else (\n",
    "                    \"ecco_profile\" if \"ecco_profile\" in row else None)\n",
    "        #else:\n",
    "            # For ASTE, ORAS5, GLORYS, just use \"Profile\" always\n",
    "           # if \"Profile\" in row:\n",
    "                #profile_col = \"Profile\"\n",
    "            #else:\n",
    "                #print(f\"No profile column found for {normalized_type} in row index {_}\")\n",
    "                #continue\n",
    "        if profile_col is None:\n",
    "            raise ValueError(\"No profile column found in CSV!\")\n",
    "\n",
    "        if profile_col is None:\n",
    "            print(f\"No profile column found for {normalized_type} in row index {_}\")\n",
    "            continue\n",
    "\n",
    "        profile = clean_profile(row[profile_col])\n",
    "        if len(profile) == 0:\n",
    "            continue\n",
    "\n",
    "        # Find matching CTD file\n",
    "        ctd_file = row[\"CTD_file\"]\n",
    "        region = row[\"Region\"]\n",
    "        match_path = [p for p in omg_paths if ctd_file in os.path.basename(p)]\n",
    "        if not match_path:\n",
    "            print(\"NO MATCH:\", ctd_file)\n",
    "            continue\n",
    "        ctd_path = match_path[0]\n",
    "\n",
    "        # Read CTD profile\n",
    "        ctd_depths, ctd_values = read_ctd_profile(ctd_path, normalized_type)\n",
    "        if ctd_values is None or len(ctd_values) == 0 or ctd_depths is None or len(ctd_depths) == 0:\n",
    "            continue\n",
    "\n",
    "        # Interpolate\n",
    "        interp_len = min(len(profile), len(ctd_values))\n",
    "        common_depths = np.linspace(ctd_depths.min(), ctd_depths.max(), interp_len)\n",
    "        ctd_interp = np.interp(common_depths, ctd_depths, ctd_values)\n",
    "        model_interp = np.interp(\n",
    "            common_depths,\n",
    "            np.linspace(ctd_depths.min(), ctd_depths.max(), len(profile)),\n",
    "            profile\n",
    "        )\n",
    "\n",
    "        diff = model_interp - ctd_interp\n",
    "        mean_diff = np.nanmean(diff)\n",
    "\n",
    "        summary_rows.append({\n",
    "            \"CTD_file\": ctd_file,\n",
    "            \"File_ID\": row[\"File_ID\"],\n",
    "            \"Var_type\": normalized_type,\n",
    "            \"Region\": region,\n",
    "            \"OMG_Mean\": float(np.nanmean(ctd_interp)),\n",
    "            \"Model_Mean\": float(np.nanmean(model_interp)),\n",
    "            \"Difference\": float(mean_diff),\n",
    "            \"Model_Profile\": profile,\n",
    "            \"depth_profile\": clean_profile(row.get(\"depth_profile\", [])),\n",
    "            \"omg_depth\": clean_profile(row.get(\"omg_depth\", [])),\n",
    "            \"Profile_Diff\": diff.tolist()\n",
    "        })\n",
    "\n",
    "    # Save output\n",
    "    summary_df = pd.DataFrame(summary_rows)\n",
    "    summary_df.to_csv(output_name, index=False)\n",
    "    print(f\"Saved summary to: {output_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9f3faa52-5787-437c-928f-249d41503bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findDiffs(model_csv, output_name, var_type_name, is_ecco=False, is_temp=False):\n",
    "    import os\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "    # get OMG netCDF paths\n",
    "    omg_paths = get_all_nc_files(\"/Users/sherine_aldrin/Downloads/CoOL/Comparing_Models/OMG_data\")\n",
    "    region_info = pd.read_csv(\n",
    "        \"/Users/sherine_aldrin/Downloads/CoOL/Comparing_Models/OMG_CTD_Locations_2016_2017_with_region.csv\"\n",
    "    )\n",
    "\n",
    "    # work on a copy\n",
    "    df = model_csv.copy()\n",
    "\n",
    "    # Detect CTD_file column\n",
    "    possible_ctd_cols = [\"CTD_file\", \"file\", \"File_ID\"]\n",
    "    for col in possible_ctd_cols:\n",
    "        if col in df.columns:\n",
    "            df[\"CTD_file\"] = df[col]\n",
    "            break\n",
    "    if \"CTD_file\" not in df.columns:\n",
    "        raise ValueError(\"Could not find CTD file column in input CSV\")\n",
    "\n",
    "    # Derive File_ID\n",
    "    df[\"File_ID\"] = (\n",
    "        df[\"CTD_file\"]\n",
    "        .astype(str)\n",
    "        .str.replace(\"CTD_\", \"\", regex=False)\n",
    "        .str.replace(\".nc\", \"\", regex=False)\n",
    "    )\n",
    "\n",
    "    # Merge region info if missing\n",
    "    if \"Region\" not in df.columns:\n",
    "        df = df.merge(region_info[[\"File_ID\", \"Region\"]], on=\"File_ID\", how=\"left\")\n",
    "    df[\"Region\"] = df[\"Region\"].fillna(\"Unassigned\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # Determine profile column ONCE\n",
    "    # -----------------------------\n",
    "    if is_ecco:\n",
    "        if var_type_name.lower() in [\"theta\", \"temperature\"]:\n",
    "            if \"ecco_profile_temp\" in df.columns:\n",
    "                profile_col = \"ecco_profile_temp\"\n",
    "            elif \"ecco_profile\" in df.columns:\n",
    "                profile_col = \"ecco_profile\"\n",
    "            else:\n",
    "                profile_col = None\n",
    "        else:  # salinity\n",
    "            if \"ecco_profile_salt\" in df.columns:\n",
    "                profile_col = \"ecco_profile_salt\"\n",
    "            elif \"ecco_profile\" in df.columns:\n",
    "                profile_col = \"ecco_profile\"\n",
    "            else:\n",
    "                profile_col = None\n",
    "    else:\n",
    "        # ASTE, ORAS5, GLORYS all use \"Profile\"\n",
    "        profile_col = \"Profile\" if \"Profile\" in df.columns else None\n",
    "\n",
    "    if profile_col is None:\n",
    "        raise ValueError(\"No appropriate profile column found in the CSV.\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # Iterate over rows\n",
    "    # -----------------------------\n",
    "    summary_rows = []\n",
    "    for _, row in df.iterrows():\n",
    "        # Determine variable type\n",
    "        if \"Var_type\" in df.columns:\n",
    "            var_type = row[\"Var_type\"] if pd.notna(row[\"Var_type\"]) else var_type_name\n",
    "        elif \"Variable\" in df.columns:\n",
    "            var_type = row[\"Variable\"] if pd.notna(row[\"Variable\"]) else var_type_name\n",
    "        else:\n",
    "            var_type = var_type_name\n",
    "\n",
    "        if str(var_type).upper() in [\"THETA\", \"TEMPERATURE\"]:\n",
    "            normalized_type = \"Theta\"\n",
    "        elif str(var_type).upper() in [\"SALT\", \"SALINITY\"]:\n",
    "            normalized_type = \"Salinity\"\n",
    "        else:\n",
    "            print(f\"Skipping unknown Var_type: {var_type}\")\n",
    "            continue\n",
    "\n",
    "        # Clean the profile data\n",
    "        profile = clean_profile(row[profile_col])\n",
    "        if len(profile) == 0:\n",
    "            continue\n",
    "\n",
    "        # Find matching CTD file\n",
    "        ctd_file = row[\"CTD_file\"]\n",
    "        region = row[\"Region\"]\n",
    "        match_path = [p for p in omg_paths if ctd_file in os.path.basename(p)]\n",
    "        if not match_path:\n",
    "            print(\"NO MATCH:\", ctd_file)\n",
    "            continue\n",
    "        ctd_path = match_path[0]\n",
    "\n",
    "        # Read CTD profile\n",
    "        ctd_depths, ctd_values = read_ctd_profile(ctd_path, normalized_type)\n",
    "        if ctd_values is None or len(ctd_values) == 0 or ctd_depths is None or len(ctd_depths) == 0:\n",
    "            continue\n",
    "\n",
    "        # Interpolate to common depths\n",
    "        interp_len = min(len(profile), len(ctd_values))\n",
    "        common_depths = np.linspace(ctd_depths.min(), ctd_depths.max(), interp_len)\n",
    "        ctd_interp = np.interp(common_depths, ctd_depths, ctd_values)\n",
    "        model_interp = np.interp(\n",
    "            common_depths,\n",
    "            np.linspace(ctd_depths.min(), ctd_depths.max(), len(profile)),\n",
    "            profile\n",
    "        )\n",
    "\n",
    "        diff = model_interp - ctd_interp\n",
    "        mean_diff = np.nanmean(diff)\n",
    "\n",
    "        if is_temp:\n",
    "            summary_rows.append({\n",
    "            \"CTD_file\": ctd_file,\n",
    "            \"File_ID\": row[\"File_ID\"],\n",
    "            \"Var_type\": normalized_type,\n",
    "            \"Region\": region,\n",
    "            \"OMG_Mean\": float(np.nanmean(ctd_interp)),\n",
    "            \"Model_Mean\": float(np.nanmean(model_interp)),\n",
    "            \"Difference\": float(mean_diff),\n",
    "            \"Model_Profile\": profile,\n",
    "            \"depth_profile\": clean_profile(row.get(\"depth_profile_x\", [])),\n",
    "            \"omg_depth\": clean_profile(row.get(\"omg_depth_x\", [])),\n",
    "            \"Profile_Diff\": diff.tolist()\n",
    "        })\n",
    "        \n",
    "        \n",
    "        else:\n",
    "            summary_rows.append({\n",
    "            \"CTD_file\": ctd_file,\n",
    "            \"File_ID\": row[\"File_ID\"],\n",
    "            \"Var_type\": normalized_type,\n",
    "            \"Region\": region,\n",
    "            \"OMG_Mean\": float(np.nanmean(ctd_interp)),\n",
    "            \"Model_Mean\": float(np.nanmean(model_interp)),\n",
    "            \"Difference\": float(mean_diff),\n",
    "            \"Model_Profile\": profile,\n",
    "            \"depth_profile\": clean_profile(row.get(\"depth_profile\", [])),\n",
    "            \"omg_depth\": clean_profile(row.get(\"omg_depth\", [])),\n",
    "            \"Profile_Diff\": diff.tolist()\n",
    "        })\n",
    "\n",
    "    # Save output\n",
    "    summary_df = pd.DataFrame(summary_rows)\n",
    "    summary_df.to_csv(output_name, index=False)\n",
    "    print(f\"Saved summary to: {output_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5293cb58-5440-477f-8ac2-c44e43a73b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved summary to: summary_ECCO_temp.csv\n",
      "Saved summary to: summary_ECCO_salt.csv\n"
     ]
    }
   ],
   "source": [
    "ecco_temp = ecco_csv[ecco_csv[\"Var_type\"].str.upper() == \"THETA\"]\n",
    "ecco_salt = ecco_csv[ecco_csv[\"Var_type\"].str.upper() == \"SALT\"]\n",
    "\n",
    "findDiffs(ecco_temp, \"summary_ECCO_temp.csv\", var_type_name=\"Theta\", is_ecco=True)\n",
    "findDiffs(ecco_salt, \"summary_ECCO_salt.csv\", var_type_name=\"Salinity\", is_ecco=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9e848034-260a-482e-bdff-681560fd922b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved summary to: test_summary_ASTE_temp.csv\n",
      "Saved summary to: test_summary_ASTE_salt.csv\n"
     ]
    }
   ],
   "source": [
    "#aste_temp = aste_csv[aste_csv[\"Var_type\"].str.upper() == \"THETA\"]\n",
    "#aste_salt = aste_df[aste_csv[\"Var_type\"].str.upper() == \"SALT\"]\n",
    "# ValueError: No appropriate profile column found in the CSV.\n",
    "\n",
    "aste_temp = aste_csv[aste_csv[\"Var_type\"].str.upper() == \"THETA\"]\n",
    "aste_salt = aste_csv[aste_csv[\"Var_type\"].str.upper() == \"SALT\"]\n",
    "\n",
    "findDiffs(aste_temp, \"test_summary_ASTE_temp.csv\", var_type_name=\"Theta\", is_ecco=False, is_temp=True)\n",
    "findDiffs(aste_salt, \"test_summary_ASTE_salt.csv\", var_type_name=\"Salinity\", is_ecco=False, is_temp=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6bfa0aa2-aea2-45a1-b036-563ba8e56ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved summary to: summary_ORAS5_temp.csv\n",
      "Saved summary to: summary_ORAS5_salt.csv\n"
     ]
    }
   ],
   "source": [
    "oras5_temp = oras5_csv[oras5_csv[\"Var_type\"].str.upper() == \"THETA\"]\n",
    "oras5_salt = oras5_csv[oras5_csv[\"Var_type\"].str.upper() == \"SALINITY\"]\n",
    "\n",
    "findDiffs(oras5_temp, \"summary_ORAS5_temp.csv\", var_type_name=\"Theta\")\n",
    "findDiffs(oras5_salt, \"summary_ORAS5_salt.csv\", var_type_name=\"Salinity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "593ef8f2-c9e6-44f9-9165-8d893aef07dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved summary to: summary_GLORYS_temp.csv\n",
      "Saved summary to: summary_GLORYS_salt.csv\n"
     ]
    }
   ],
   "source": [
    "glorys_temp = glorys_csv[glorys_csv[\"Var_type\"].str.upper() == \"THETA\"]\n",
    "glorys_salt = glorys_csv[glorys_csv[\"Var_type\"].str.upper() == \"SALINITY\"]\n",
    "\n",
    "findDiffs(glorys_temp, \"summary_GLORYS_temp.csv\", var_type_name=\"Theta\")\n",
    "findDiffs(glorys_salt, \"summary_GLORYS_salt.csv\", var_type_name=\"Salinity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a281eb18-844d-4305-b412-5283115839bd",
   "metadata": {},
   "source": [
    "### Box Plots!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "75235156-9c29-43f8-b8c5-14357baddcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read each model's summary\n",
    "ecco_df = pd.read_csv(\"summary_ECCO_temp.csv\")\n",
    "aste_df = pd.read_csv(\"test_summary_ASTE_temp.csv\")\n",
    "oras5_df = pd.read_csv(\"summary_ORAS5_temp.csv\")\n",
    "glorys_df = pd.read_csv(\"summary_GLORYS_temp.csv\")\n",
    "\n",
    "# Add model column\n",
    "ecco_df[\"Model\"] = \"ECCO\"\n",
    "aste_df[\"Model\"] = \"ASTE\"\n",
    "oras5_df[\"Model\"] = \"ORAS5\"\n",
    "glorys_df[\"Model\"] = \"GLORYS\"\n",
    "\n",
    "# Combine\n",
    "combined_df = pd.concat([ecco_df, aste_df, oras5_df, glorys_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "524d5264-008a-4790-a02c-cfa67aae4420",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "80fd4550-c228-4028-b6c3-d2148a58e79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up region layout\n",
    "region_positions = {\n",
    "    \"N\": (0, 0), \"NW\": (1, 0), \"CW\": (2, 0), \"SW\": (3, 0),\n",
    "    \"NE\": (0, 1), \"CE\": (1, 1), \"SE\": (2, 1)\n",
    "}\n",
    "\n",
    "fig = plt.figure(figsize=(12, 16))\n",
    "gs = gridspec.GridSpec(4, 2, figure=fig)\n",
    "# 4 rows, 2 cols\n",
    "\n",
    "# Loop through each region\n",
    "for region, (row, col) in region_positions.items():\n",
    "    ax = fig.add_subplot(gs[row, col])\n",
    "    \n",
    "    palette = {\n",
    "    \"ECCO\": \"blue\",\n",
    "    \"ORAS5\": \"black\",\n",
    "    \"ASTE\": \"green\",\n",
    "    \"GLORYS\": \"red\"\n",
    "    }\n",
    "    \n",
    "    sns.violinplot(\n",
    "        data=combined_df[combined_df[\"Region\"] == region],\n",
    "        x=\"Model\",\n",
    "        y=\"Difference\",\n",
    "        ax=ax,\n",
    "        hue=\"Model\",\n",
    "        palette=palette,\n",
    "        #showfliers=False\n",
    "    )\n",
    "    \n",
    "    ax.set_title(f\"Region: {region}\")\n",
    "    ax.axhline(0, color=\"black\", linestyle=\"--\", linewidth=1)\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_ylabel(\"Difference\")\n",
    "\n",
    "# Hide unused subplot (bottom-right in 4x2 grid)\n",
    "if (3, 1) not in region_positions.values():\n",
    "    fig.add_subplot(gs[3, 1]).axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle(\"Model vs OMG Temp Differences by Region\", fontsize=16, y=0.99)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Violin_TEMP_model_vs_omg_by_region.png\", dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0995ac-0ba2-45ac-bf1e-82eeef44eeaf",
   "metadata": {},
   "source": [
    "### Now for Salinity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "84eda536-ed52-4c9d-84c9-9c2c0c1aade4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read each model's summary\n",
    "ecco_df = pd.read_csv(\"summary_ECCO_salt.csv\")\n",
    "aste_df = pd.read_csv(\"test_summary_ASTE_salt.csv\")\n",
    "oras5_df = pd.read_csv(\"summary_ORAS5_salt.csv\")\n",
    "glorys_df = pd.read_csv(\"summary_GLORYS_salt.csv\")\n",
    "\n",
    "# Add model column\n",
    "ecco_df[\"Model\"] = \"ECCO\"\n",
    "aste_df[\"Model\"] = \"ASTE\"\n",
    "oras5_df[\"Model\"] = \"ORAS5\"\n",
    "glorys_df[\"Model\"] = \"GLORYS\"\n",
    "\n",
    "# Combine\n",
    "combined_df = pd.concat([ecco_df, aste_df, oras5_df, glorys_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3b8e1f72-bc44-438a-b863-67bc1b9cf026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up region layout\n",
    "region_positions = {\n",
    "    \"N\": (0, 0), \"NW\": (1, 0), \"CW\": (2, 0), \"SW\": (3, 0),\n",
    "    \"NE\": (0, 1), \"CE\": (1, 1), \"SE\": (2, 1)\n",
    "}\n",
    "\n",
    "fig = plt.figure(figsize=(12, 16))\n",
    "gs = gridspec.GridSpec(4, 2, figure=fig)\n",
    "# 4 rows, 2 cols\n",
    "\n",
    "# Loop through each region\n",
    "for region, (row, col) in region_positions.items():\n",
    "    ax = fig.add_subplot(gs[row, col])\n",
    "    \n",
    "    palette = {\n",
    "    \"ECCO\": \"blue\",\n",
    "    \"ORAS5\": \"black\",\n",
    "    \"ASTE\": \"green\",\n",
    "    \"GLORYS\": \"red\"\n",
    "    }\n",
    "    \n",
    "    sns.violinplot(\n",
    "        data=combined_df[combined_df[\"Region\"] == region],\n",
    "        x=\"Model\",\n",
    "        y=\"Difference\",\n",
    "        ax=ax,\n",
    "        hue=\"Model\",\n",
    "        palette=palette,\n",
    "    )\n",
    "    \n",
    "    ax.set_title(f\"Region: {region}\")\n",
    "    ax.axhline(0, color=\"black\", linestyle=\"--\", linewidth=1)\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_ylabel(\"Difference\")\n",
    "\n",
    "# Hide unused subplot (bottom-right in 4x2 grid)\n",
    "if (3, 1) not in region_positions.values():\n",
    "    fig.add_subplot(gs[3, 1]).axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle(\"Model vs OMG Salinity Differences by Region\", fontsize=16, y=0.99)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Violin_SALT_model_vs_omg_by_region.png\", dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71a9279-e84f-4860-b377-652669b4cda7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oceanModeling",
   "language": "python",
   "name": "oceanmodeling"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
